{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = [0.485, 0.456, 0.406]\n",
    "channel_stds  = [0.229, 0.224, 0.225]\n",
    "#################################################################################################\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.train = train\n",
    "        self.files = os.listdir(self.image_paths)\n",
    "        self.labels = os.listdir(self.target_paths)\n",
    "        \n",
    "        self.color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1)\n",
    "\n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(256, 256))\n",
    "        image = resize(image)\n",
    "        mask = resize(mask)\n",
    "        \n",
    "        # Random transformations only for training\n",
    "        if self.train:\n",
    "            # Random horizontal flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "\n",
    "            # Random vertical flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                mask = TF.vflip(mask)\n",
    "\n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        \n",
    "        # Normalize\n",
    "        image = TF.normalize(image, channel_means, channel_stds)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_name = self.labels[idx]\n",
    "        image = Image.open(os.path.join(self.image_paths, img_name))\n",
    "\n",
    "        # Color jitter only for training\n",
    "        if self.train:\n",
    "            image = self.color_jitter(image)\n",
    "        \n",
    "        mask = Image.open(os.path.join(self.target_paths, label_name)).convert(\"L\")\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y, img_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMG_tr  = os.path.join(\"./train/\"\n",
    "                        , 'images')\n",
    "DIR_MASK_tr = os.path.join(\"./train/\"\n",
    "                        , 'masks')\n",
    "DIR_IMG_v  = os.path.join(\"./validation/\"\n",
    "                        , 'images')\n",
    "DIR_MASK_v = os.path.join(\"./validation/\"\n",
    "                        , 'masks')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_T = MyDataset(DIR_IMG_tr, DIR_MASK_tr)\n",
    "dataset_V = MyDataset(DIR_IMG_v, DIR_MASK_v, train=False)\n",
    "#Batch Size and Loaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(dataset_T, batch_size, shuffle=True, \n",
    "                          pin_memory=torch.cuda.is_available())\n",
    "valid_loader = DataLoader(dataset_V, batch_size, shuffle=False, \n",
    "                          pin_memory= torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input, target, img_name, label_name) in enumerate(valid_loader):\n",
    "    \n",
    "    #To Device\n",
    "    input_var  = input.cuda()\n",
    "    target_var = torch.round(target.cuda())\n",
    "    print(input_var.shape, target_var.shape)\n",
    "    \n",
    "    plt.imshow(input_var[0].cpu().permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.imshow(target_var[0][0].cpu())\n",
    "    plt.show()\n",
    "    #print(torch.unique(target))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_UnSupervised(Dataset):\n",
    "    def __init__(self, image_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.files = os.listdir(self.image_paths)\n",
    "\n",
    "    def transform(self, image):  \n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(256, 256))\n",
    "        image = resize(image)\n",
    "        \n",
    "        # Random horizontal flipping\n",
    "        if random.random() > 0.2:\n",
    "            image = TF.hflip(image)    \n",
    "        # Random vertical flipping\n",
    "        if random.random() > 0.2:\n",
    "            image = TF.vflip(image)  \n",
    "            \n",
    "        # Random vertical flipping\n",
    "        image2 = image.copy()\n",
    "        \n",
    "        t_c = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)\n",
    "        t_g = transforms.GaussianBlur(5, sigma=(0.1, 2.0))\n",
    "        \n",
    "        image2 = t_c(image2) \n",
    "        \n",
    "        if random.random() < 0.3:\n",
    "            image2 = t_g(image2) \n",
    "             \n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image) \n",
    "        image2 = TF.to_tensor(image2) \n",
    "        \n",
    "        #Normalise\n",
    "        image = TF.normalize(image, channel_means, channel_stds)\n",
    "        image2 = TF.normalize(image2, channel_means, channel_stds)\n",
    "        return image, image2\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.files[idx]\n",
    "        image = Image.open(os.path.join(self.image_paths,img_name))\n",
    "        image, image2 = self.transform(image)\n",
    "        return image, image2, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMG  = os.path.join(\"./unlabelled/\"\n",
    "                        , 'images')\n",
    "\n",
    "dataset_Unsupervised = MyDataset_UnSupervised(DIR_IMG)\n",
    "\n",
    "#Batch Size and Loaders\n",
    "batch_size_unsupervised = 8\n",
    "unsupervised_loader = DataLoader(dataset_Unsupervised, batch_size_unsupervised, shuffle = True, \n",
    "                          pin_memory=torch.cuda.is_available())#torch.cuda.is_available())\n",
    "print(len(dataset_Unsupervised)/batch_size_unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i, (image, image2, img_name) in enumerate(unsupervised_loader):\n",
    "    \n",
    "    plt.imshow(image[0].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.imshow(image2[0].permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Input\", input_var.shape, img_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMG_T  = os.path.join(\"./Test/\", 'images')\n",
    "DIR_MASK_T = os.path.join(\"./Test/\", 'masks')\n",
    "dataset_T = MyDataset(DIR_IMG_T, DIR_MASK_T, train = False)\n",
    "\n",
    "#Batch Size and Loaders\n",
    "batch_size_T = batch_size\n",
    "test_loader = DataLoader(dataset_T, batch_size_T, shuffle=False, pin_memory=torch.cuda.is_available())#torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loss import IoULoss\n",
    "seg_loss = IoULoss()\n",
    "CEloss = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import scipy.ndimage as ndimage\n",
    "\n",
    "def train(train_loader, model,\n",
    "          optimizer_, validation,\n",
    "          MVL = 10, scheduler_=None):\n",
    "\n",
    "    TrEpochsloss_Su = []\n",
    "    TrEpochsloss_Unsu = []\n",
    "    ValEpochsloss = []\n",
    "    \n",
    "    #Initial min_val_loss\n",
    "    min_val_los = MVL\n",
    "\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "            \n",
    "        Supervisedloss = []    \n",
    "        Unsupervisedloss = []\n",
    "        \n",
    "        model.train()\n",
    "        ###################################################################################################\n",
    "        dataloader_iterator = iter(train_loader)  ########################### S dataset\n",
    "        for i, (image1, image2, image_name) in enumerate(unsupervised_loader): ######## L dataset\n",
    "            ## S\n",
    "            try:\n",
    "                input, target, img_name, label_name = next(dataloader_iterator)\n",
    "            except StopIteration:\n",
    "                dataloader_iterator = iter(train_loader)    ################## S dataset\n",
    "                input, target, img_name, label_name = next(dataloader_iterator)\n",
    "            ##--------------------------------------------------\n",
    "            #Target and Input\n",
    "            ##--------------------------------------------------\n",
    "            target = torch.round(target)\n",
    "            #---------------------------------------------------\n",
    "            ## Supervised\n",
    "            #---------------------------------------------------\n",
    "            #Model the input\n",
    "            masks_su = model(input.cuda())\n",
    "            masks_su = torch.sigmoid(masks_su)\n",
    "            #Calcualte the Loss\n",
    "            loss_Su = seg_loss(masks_su, target.cuda().squeeze(1).long())\n",
    "            #Step loss appending\n",
    "            Supervisedloss.append(loss_Su.item())\n",
    "            \n",
    "            #---------------------------------------------------\n",
    "            ## Semi-Supervised\n",
    "            #---------------------------------------------------\n",
    "            #Model the input\n",
    "            ###############################################Model\n",
    "            masks_unsu1 = model(image1.cuda())\n",
    "            masks_unsu1 = torch.sigmoid(masks_unsu1)\n",
    "                                        \n",
    "            masks_unsu2 = model(image2.cuda())\n",
    "            masks_unsu2 = torch.sigmoid(masks_unsu2)\n",
    "                                        \n",
    "            #Calcualte the Loss\n",
    "            loss_Unsu = seg_loss(masks_unsu2, torch.round(masks_unsu1).detach().float().cuda().squeeze(1))\n",
    "\n",
    "            #Step loss appending\n",
    "            Unsupervisedloss.append(loss_Unsu.item())\n",
    "            \n",
    "            beta = 1\n",
    "            ### Losesse (Sup + UNSup)\n",
    "            Loss = (loss_Su + beta * loss_Unsu)/(1+beta)\n",
    "            \n",
    "            # compute gradient and do SGD step            \n",
    "            Loss.backward()\n",
    "\n",
    "            #updating parameters of the model\n",
    "            #Teacher1\n",
    "            optimizer_.step()\n",
    "            optimizer_.zero_grad()\n",
    "\n",
    "            sys.stdout.write(\"\\r Training %d/%d |M Su: %.3f Unsu: %.3f|\"\\\n",
    "                 % (i, len(unsupervised_loader.dataset)/unsupervised_loader.batch_size, \n",
    "                    loss_Su.item(), loss_Unsu.item()))\n",
    "            sys.stdout.flush()\n",
    "          \n",
    "        #Validation for one epoch\n",
    "        valid_metrics = validation(model, valid_loader)\n",
    "        valid_loss = valid_metrics['valid_loss']\n",
    "        ###################################################################################\n",
    "        \n",
    "        #Saving Epochs Loss for Train and Validation\n",
    "        #model     \n",
    "        TrEpochsloss_Su.append(np.mean(Supervisedloss))\n",
    "        TrEpochsloss_Unsu.append(np.mean(Unsupervisedloss))\n",
    "        ValEpochsloss.append(valid_loss)\n",
    "        \n",
    "        ##PRITNIGN ONE EPOCH OUTCOME\n",
    "        print(\"Epoch:\", epoch, \"###########################################################\")\n",
    "        print(f'\\tTrain_loss = {np.mean(Supervisedloss):.5f}')\n",
    "        print(f'\\tTrain_loss = {np.mean(Unsupervisedloss):.5f}')\n",
    "        print(f'\\tValid_loss = {valid_loss:.5f}')\n",
    "        print(\"LR at the end of epoch=\", get_lr(optimizer_))\n",
    "        \n",
    "        #Save the model of the current epoch\n",
    "        if valid_loss < min_val_los:\n",
    "            print(\"valid_loss < min_val_loss\")\n",
    "            min_val_los = valid_loss\n",
    "            best_wts = copy.deepcopy(model.state_dict())\n",
    "            EPOCH_best = epoch\n",
    "        \n",
    "        #tune the learning rate        \n",
    "        if scheduler_ is not None:\n",
    "            scheduler_.step()\n",
    "        print()\n",
    "        \n",
    "    #Best model based on validation\n",
    "    model.load_state_dict(best_wts)\n",
    "    \n",
    "    return model, TrEpochsloss_Su, TrEpochsloss_Unsu, ValEpochsloss, EPOCH_best\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    losses = AverageMeter()\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (input, target, fname, mname) in enumerate(val_loader):\n",
    "            input_var  = input.cuda()\n",
    "            target_var = torch.round(target).cuda()\n",
    "\n",
    "            masks_pred = model(input_var)\n",
    "            masks_pred = torch.sigmoid(masks_pred)\n",
    "            \n",
    "            loss = seg_loss(masks_pred, target_var.squeeze(1).long())\n",
    "\n",
    "            losses.update(loss.item(), input_var.size(0))\n",
    "\n",
    "    return {'valid_loss': losses.avg}\n",
    "\n",
    "def save_check_point(state, is_best, file_name = 'checkpoint.pth.tar'):\n",
    "    torch.save(state, file_name)\n",
    "    if is_best:\n",
    "        shutil.copy(file_name, 'model_best.pth.tar')\n",
    "\n",
    "def calc_crack_pixel_weight(mask_dir):\n",
    "    avg_w = 0.0\n",
    "    n_files = 0\n",
    "    for path in Path(mask_dir).glob('*.*'):\n",
    "        n_files += 1\n",
    "        m = ndimage.imread(path)\n",
    "        ncrack = np.sum((m > 0)[:])\n",
    "        w = float(ncrack)/(m.shape[0]*m.shape[1])\n",
    "        avg_w = avg_w + (1-w)\n",
    "\n",
    "    avg_w /= float(n_files)\n",
    "\n",
    "    return avg_w / (1.0 - avg_w)\n",
    "\n",
    "##@@@#@#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "##@@@#@#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Epochs\n",
    "start_epoch = 0 # start from start_epoch\n",
    "end_epoch = 51 # the last epoch is end_epoch-1\n",
    "\n",
    "optimizer1 = torch.optim.SGD(model.parameters(), lr = 0.0005, momentum=0.9, weight_decay=1e-3)\n",
    "scheduler1 = torch.optim.lr_scheduler.StepLR(optimizer1, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"Sup_St1.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, TrEpochsloss_M1_Su, TrEpochsloss_M1_Unsu, ValEpochsloss_M1, EPOCH_best_M1 = \\\n",
    "train(train_loader, model,\n",
    "          optimizer1, validate,\n",
    "          MVL = 1, scheduler_ = scheduler1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Semisup.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_A(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, train=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.files = os.listdir(self.image_paths)\n",
    "        self.lables = os.listdir(self.target_paths)\n",
    "        \n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(256, 256))\n",
    "        image = resize(image)\n",
    "        mask = resize(mask)\n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        \n",
    "        #Normalise\n",
    "        image = TF.normalize(image, channel_means, channel_stds)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_name = self.lables[idx]\n",
    "        image = Image.open(os.path.join(self.image_paths,img_name))\n",
    "        mask = Image.open(os.path.join(self.target_paths,label_name)).convert(\"L\")\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y, img_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    return (2 * (y_true * y_pred).sum() + 1e-15) / (y_true.sum() + y_pred.sum() + 1e-15)\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    union = y_true.sum() + y_pred.sum() - intersection\n",
    "    return (intersection + 1e-15) / (union + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data path\n",
    "DIR_IMG_test  = os.path.join(\"./test/\", \n",
    "                             'images')\n",
    "DIR_MASK_test = os.path.join(\"./test/\", \n",
    "                             'masks')\n",
    "dataset_test = MyDataset_A(DIR_IMG_test, DIR_MASK_test)\n",
    "\n",
    "#Batch Size and Loader\n",
    "batch_size = 1\n",
    "test_loader_A = DataLoader(dataset_test, batch_size, shuffle=False, \n",
    "                          pin_memory=torch.cuda.is_available())\n",
    "print(len(test_loader_A.dataset))\n",
    "\n",
    "DICE = []\n",
    "MIOU = []\n",
    "k = 0\n",
    "\n",
    "# running the test loop   \n",
    "with torch.no_grad():\n",
    "\n",
    "    model.eval()\n",
    "    for i, (input, target, fname, MNAME) in enumerate(test_loader_A):\n",
    "\n",
    "        #To Device\n",
    "        input_var  = input.cuda()\n",
    "        target_var = torch.round(target).cuda()\n",
    "        k = k + 1\n",
    "        #Torch Autocast\n",
    "        with autocast():\n",
    "\n",
    "            #Model the input\n",
    "            masks_pred = model(input_var)\n",
    "            ## Probabiliteis\n",
    "            masks_pred = F.sigmoid(masks_pred)\n",
    "            #round the probabiliteis to zeros and ones\n",
    "            masks_pred = torch.round(masks_pred)\n",
    "\n",
    "            #Making sure they are both tensors\n",
    "            target_var = torch.tensor(target_var)\n",
    "            masks_pred = torch.tensor(masks_pred)\n",
    "\n",
    "            #calcualting Dice and IoU\n",
    "            dice_score = dice(masks_pred, target_var[0])\n",
    "            jaccard_score = jaccard(masks_pred, target_var[0])\n",
    "\n",
    "            #Appending the calculated metrics\n",
    "            DICE.append(dice_score.item())\n",
    "            MIOU.append(jaccard_score.item())\n",
    "\n",
    "print(\"Dice\", np.mean(np.array(DICE)), np.std(np.array(DICE)))\n",
    "print(\"IoU\", np.mean(np.array(MIOU)), np.std(np.array(MIOU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
