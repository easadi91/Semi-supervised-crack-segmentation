{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7924a",
   "metadata": {},
   "source": [
    "#### DataLoader Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_means = [0.485, 0.456, 0.406]\n",
    "channel_stds  = [0.229, 0.224, 0.225]\n",
    "#################################################################################################\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, train=True):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.train = train\n",
    "        self.files = os.listdir(self.image_paths)\n",
    "        self.labels = os.listdir(self.target_paths)\n",
    "        \n",
    "        self.color_jitter = transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1)\n",
    "\n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(256, 256))\n",
    "        image = resize(image)\n",
    "        mask = resize(mask)\n",
    "        \n",
    "        # Random transformations only for training\n",
    "        if self.train:\n",
    "            # Random horizontal flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "\n",
    "            # Random vertical flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                mask = TF.vflip(mask)\n",
    "\n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        \n",
    "        # Normalize\n",
    "        image = TF.normalize(image, channel_means, channel_stds)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_name = self.labels[idx]\n",
    "        image = Image.open(os.path.join(self.image_paths, img_name))\n",
    "\n",
    "        # Color jitter only for training\n",
    "        if self.train:\n",
    "            image = self.color_jitter(image)\n",
    "        \n",
    "        mask = Image.open(os.path.join(self.target_paths, label_name)).convert(\"L\")\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y, img_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f28b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_IMG_tr  = os.path.join(\"./Data_FR/\" # this path here changes based on the step at stage 3\n",
    "                        , 'images')\n",
    "DIR_MASK_tr = os.path.join(\"./Data_FR/\" # this path here changes based on the step at stage 3\n",
    "                        , 'masks')\n",
    "DIR_IMG_v  = os.path.join(\"./validation/\"\n",
    "                        , 'images')\n",
    "DIR_MASK_v = os.path.join(\"./validation/\"\n",
    "                        , 'masks')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_T = MyDataset(DIR_IMG_tr, DIR_MASK_tr)\n",
    "dataset_V = MyDataset(DIR_IMG_v, DIR_MASK_v, train=False)\n",
    "#Batch Size and Loaders\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(dataset_T, batch_size, shuffle=True, \n",
    "                          pin_memory=torch.cuda.is_available())\n",
    "valid_loader = DataLoader(dataset_V, batch_size, shuffle=False, \n",
    "                          pin_memory= torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input, target, img_name, label_name) in enumerate(train_loader):\n",
    "\n",
    "    #To Device\n",
    "    input_var  = input.cuda()\n",
    "    target_var = torch.round(target).cuda()\n",
    "    print(input_var.shape, target_var.shape)\n",
    "    plt.imshow(input_var[1].cpu().permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    plt.imshow(target_var[1].cpu().permute(1, 2, 0))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fddf558",
   "metadata": {},
   "source": [
    "#### Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import scipy.ndimage as ndimage\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "def train(train_loader, model, optimizer, validation, scheduler=None, G_A = 2):\n",
    "    #best_model_wts = model.state_dict()\n",
    "\n",
    "    #List to Append all losses of Train and Val Epochs\n",
    "    Validation_losses = []\n",
    "    Train_losses = []\n",
    "    \n",
    "    #Initial min_val_loss\n",
    "    min_val_los = 10\n",
    "    \n",
    "    #Gradient ACcumaltion Size\n",
    "    gradient_accumulations = G_A\n",
    "    \n",
    "    #torch amp scaler\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    model.zero_grad()\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        trn_loss = []\n",
    "        valid_losses = []\n",
    "        losses = AverageMeter()\n",
    "\n",
    "        model.train()\n",
    "        for i, (input, target, fname, mname) in enumerate(train_loader):\n",
    "            \n",
    "            #To Device\n",
    "            input_var  = input.cuda()\n",
    "            target_var = torch.round(target).cuda()\n",
    "            \n",
    "            #Torch Autocast\n",
    "            with autocast():\n",
    "                \n",
    "                #Model the input\n",
    "                masks_pred = model(input_var)\n",
    "                masks_pred = torch.sigmoid(masks_pred)\n",
    "                \n",
    "                #Calcualte the Loss\n",
    "                loss = seg_loss(masks_pred, target_var.squeeze(1).long())\n",
    "            \n",
    "            #Step loss appending\n",
    "            trn_loss.append(loss)\n",
    "            losses.update(loss)\n",
    "\n",
    "            # compute gradient and do SGD step            \n",
    "            scaler.scale(loss / gradient_accumulations).backward()\n",
    "                \n",
    "            #updating parameters of the model\n",
    "            if (i + 1) % gradient_accumulations == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                model.zero_grad()\n",
    "                \n",
    "        #Validation for one epoch\n",
    "        valid_metrics = validation(model, valid_loader)\n",
    "        valid_loss = valid_metrics['valid_loss']\n",
    "        \n",
    "        #Saving Epochs Loss for Train and Validation\n",
    "        Train_losses.append(np.mean(torch.stack(trn_loss).detach().cpu().numpy()))\n",
    "        Validation_losses.append(valid_loss)\n",
    "        \n",
    "        ##PRITNIGN ONE EPOCH OUTCOME\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(f'\\tTrain_loss = {np.mean(torch.stack(trn_loss).detach().cpu().numpy()):.5f}')\n",
    "        print(f'\\tValid_loss = {valid_loss:.5f}')\n",
    "        print(\"LR at the end of epoch=\", get_lr(optimizer))\n",
    "        print()\n",
    "\n",
    "        #Save the model of the current epoch\n",
    "        if valid_loss < min_val_los:\n",
    "            print(\"valid_loss < min_val_los\")\n",
    "            min_val_los = valid_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, Train_losses, Validation_losses, best_model_wts\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    losses = AverageMeter()\n",
    "    model.train(False)\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target, fname, mname) in enumerate(val_loader):\n",
    "            input_var  = input.cuda()\n",
    "            target_var = torch.round(target).cuda()\n",
    "            masks_pred = model(input_var)\n",
    "            masks_pred = torch.sigmoid(masks_pred)\n",
    "            loss = seg_loss(masks_pred, target_var.squeeze(1).long())\n",
    "            losses.update(loss.item(), input_var.size(0))\n",
    "    return {'valid_loss': losses.avg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24205646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count   \n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def save_check_point(state, is_best, file_name = 'checkpoint.pth.tar'):\n",
    "    torch.save(state, file_name)\n",
    "    if is_best:\n",
    "        shutil.copy(file_name, 'model_best.pth.tar')\n",
    "\n",
    "def calc_crack_pixel_weight(mask_dir):\n",
    "    avg_w = 0.0\n",
    "    n_files = 0\n",
    "    for path in Path(mask_dir).glob('*.*'):\n",
    "        n_files += 1\n",
    "        m = ndimage.imread(path)\n",
    "        ncrack = np.sum((m > 0)[:])\n",
    "        w = float(ncrack)/(m.shape[0]*m.shape[1])\n",
    "        avg_w = avg_w + (1-w)\n",
    "    avg_w /= float(n_files)\n",
    "    return avg_w / (1.0 - avg_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e167c3b",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c3b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    "    activation = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec97886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = torch.rand(1,3,256,256)\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09795bf8",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf101db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loss import IoULoss\n",
    "seg_loss = IoULoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d408d2",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd62962",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Epochs\n",
    "start_epoch = 0 #start from 0\n",
    "end_epoch = 150 # ends in 9\n",
    "\n",
    "##Directory of the Model\n",
    "model_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fa66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr = 0.01,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484f78d",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d40fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\".PTH\"))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad8bd40",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ab78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, Train_losses, Validation_losses, best_model_wts = train(train_loader, model, optimizer, validate, scheduler, G_A = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Sup_St3-Stn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cac3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a73ba",
   "metadata": {},
   "source": [
    "### Validate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313e677",
   "metadata": {},
   "source": [
    "###### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_A(Dataset):\n",
    "    def __init__(self, image_paths, target_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.files = os.listdir(self.image_paths)\n",
    "        self.lables = os.listdir(self.target_paths)\n",
    "        \n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        resize = transforms.Resize(size=(256, 256))\n",
    "        image = resize(image)\n",
    "        mask = resize(mask)\n",
    "\n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        \n",
    "        #Normalise\n",
    "        image = TF.normalize(image, channel_means, channel_stds)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.files[idx]\n",
    "        label_name = self.lables[idx]\n",
    "        image = Image.open(os.path.join(self.image_paths,img_name))\n",
    "        mask = Image.open(os.path.join(self.target_paths,label_name)).convert(\"L\")\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y, img_name, label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f61f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    return (2 * (y_true * y_pred).sum() + 1e-15) / (y_true.sum() + y_pred.sum() + 1e-15)\n",
    "\n",
    "def jaccard(y_true, y_pred):\n",
    "    intersection = (y_true * y_pred).sum()\n",
    "    union = y_true.sum() + y_pred.sum() - intersection\n",
    "    return (intersection + 1e-15) / (union + 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data path\n",
    "DIR_IMG_test  = os.path.join(\"./test/\", \n",
    "                             'images')\n",
    "DIR_MASK_test = os.path.join(\"./test/\", \n",
    "                             'masks')\n",
    "dataset_test = MyDataset_A(DIR_IMG_test, DIR_MASK_test)\n",
    "\n",
    "#Batch Size and Loader\n",
    "batch_size = 1\n",
    "test_loader_A = DataLoader(dataset_test, batch_size, shuffle=False, \n",
    "                          pin_memory=torch.cuda.is_available())\n",
    "print(len(test_loader_A.dataset))\n",
    "\n",
    "DICE = []\n",
    "MIOU = []\n",
    "k = 0\n",
    "\n",
    "\n",
    "# running the test loop   \n",
    "with torch.no_grad():\n",
    "\n",
    "    model.eval()\n",
    "    for i, (input, target, fname, MNAME) in enumerate(test_loader_A):\n",
    "\n",
    "        #To Device\n",
    "        input_var  = input.cuda()\n",
    "        target_var = torch.round(target).cuda()\n",
    "        k = k + 1\n",
    "        #Torch Autocast\n",
    "        with autocast():\n",
    "\n",
    "            #Model the input\n",
    "            masks_pred = model(input_var)\n",
    "            ## Probabiliteis\n",
    "            masks_pred = F.sigmoid(masks_pred)\n",
    "            #round the probabiliteis to zeros and ones\n",
    "            masks_pred = torch.round(masks_pred)\n",
    "\n",
    "            #Making sure they are both tensors\n",
    "            target_var = torch.tensor(target_var)\n",
    "            masks_pred = torch.tensor(masks_pred)\n",
    "\n",
    "            #calcualting Dice and IoU\n",
    "            dice_score = dice(masks_pred, target_var[0])\n",
    "            jaccard_score = jaccard(masks_pred, target_var[0])\n",
    "\n",
    "            #Appending the calculated metrics\n",
    "            DICE.append(dice_score.item())\n",
    "            MIOU.append(jaccard_score.item())\n",
    "\n",
    "\n",
    "print(\"Dice\", np.mean(np.array(DICE)), np.std(np.array(DICE)))\n",
    "\n",
    "print(\"IoU\", np.mean(np.array(MIOU)), np.std(np.array(MIOU)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test one image \n",
    "plt.imshow(torch.tensor(masks_pred)[0][0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e395bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
